#operator_tokenizer {
    #translate {
        '>'             bigger
        '<'             smaller
        '+'             add
        '-'             subtract
        '/'             divide
        '*'             multiply
        '|'             or
        '&'             and
        '!'             invert
        '~'             concatinate
        '^'             xor
        '%'             modulus
        '?'             macro
        '{'             open_curly
        '}'             close_curly
        '('             open_round
        ')'             close_round
        '['             open_square
        ']'             close_square
        '#'             selector
        '$'             image
        ':'             colon
        ','             comma
        '.'             dot
        '\\'            backslash
        ';'             semicolon
        '='             assign
        '\''            apostrophe
        '\"'            quotation
        '@'             at
    }
    #ignored        [ '\r' '\t' '\n' ' ' ]
}

#identifier_tokenizer {
    #prefix          [ _ a b c d e f g h i j k l m n o p q r s t u v w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z @@0 1 2 3 4 5 6 7 8 9@@ ]
}
